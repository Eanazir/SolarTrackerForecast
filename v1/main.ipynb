{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing/data_preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "def preprocess_meteorological_data(file_path):\n",
    "    # Load data\n",
    "    met_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Combine DATE and MST into a single datetime column\n",
    "    # met_data['Timestamp'] = pd.to_datetime(met_data['DATE'] + ' ' + met_data['MST'])\n",
    "    # Combine DATE and MST into a single datetime column\n",
    "    met_data['Timestamp'] = pd.to_datetime(met_data['datetime'].astype(str), format='%Y%m%d%H%M%S')\n",
    "\n",
    "    # Sort data by Timestamp\n",
    "    met_data.sort_values('Timestamp', inplace=True)\n",
    "\n",
    "    # Handle missing values in input features using KNN imputation\n",
    "    input_features = [\n",
    "        'Tower Dry Bulb Temp [deg C]', 'Tower RH [%]', 'Station Pressure [mBar]',\n",
    "        'Avg Wind Speed @ 6ft [m/s]', 'Avg Wind Direction @ 6ft [deg from N]'\n",
    "    ]\n",
    "\n",
    "    # Initialize KNN imputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # Fit and transform the input features\n",
    "    met_data_imputed = imputer.fit_transform(met_data[input_features])\n",
    "\n",
    "    # Update the DataFrame with imputed values\n",
    "    met_data[input_features] = met_data_imputed\n",
    "\n",
    "    # Handle missing values in the target variable separately\n",
    "    target_variable = 'Global CMP22 (vent/cor) [W/m^2]'\n",
    "\n",
    "    # Optionally interpolate missing target values\n",
    "    # met_data[target_variable].interpolate(method='time', inplace=True)\n",
    "    \n",
    "    # Option 2: Drop rows with missing target values (uncomment if preferred)\n",
    "    met_data.dropna(subset=[target_variable], inplace=True)\n",
    "\n",
    "    # Rename columns for simplicity\n",
    "    met_data.rename(columns={\n",
    "        'Tower Dry Bulb Temp [deg C]': 'Temperature',\n",
    "        'Tower RH [%]': 'Humidity',\n",
    "        'Station Pressure [mBar]': 'Pressure',\n",
    "        'Avg Wind Speed @ 6ft [m/s]': 'Wind Speed',\n",
    "        'Avg Wind Direction @ 6ft [deg from N]': 'Wind Direction',\n",
    "        'Global CMP22 (vent/cor) [W/m^2]': 'Irradiance'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Feature scaling for input features\n",
    "    scaler = MinMaxScaler()\n",
    "    met_data[['Temperature', 'Humidity', 'Pressure', 'Wind Speed']] = scaler.fit_transform(\n",
    "        met_data[['Temperature', 'Humidity', 'Pressure', 'Wind Speed']]\n",
    "    )\n",
    "    joblib.dump(scaler, 'scaler_y.pkl')\n",
    "\n",
    "    # Wind Direction encoding (convert degrees to sine and cosine components)\n",
    "    met_data['Wind Dir Sin'] = np.sin(np.deg2rad(met_data['Wind Direction']))\n",
    "    met_data['Wind Dir Cos'] = np.cos(np.deg2rad(met_data['Wind Direction']))\n",
    "    met_data.drop('Wind Direction', axis=1, inplace=True)\n",
    "\n",
    "    # Temporal features\n",
    "    met_data['Hour'] = met_data['Timestamp'].dt.hour / 23.0  # Normalize Hour\n",
    "    met_data['DayOfYear'] = met_data['Timestamp'].dt.dayofyear / 365.0  # Normalize DayOfYear\n",
    "\n",
    "    # Prepare target variables (future irradiance)\n",
    "    target = 'Irradiance'\n",
    "    for minutes in [5, 15, 30, 60]:\n",
    "        met_data[f'Irradiance_{minutes}min_ahead'] = met_data[target].shift(-minutes)\n",
    "\n",
    "    # **Removed the line that drops rows with NaN values after shifting**\n",
    "    # We will handle dropping NaN values after merging with images\n",
    "    # met_data.dropna(inplace=True)\n",
    "\n",
    "    # Reset index and return the processed DataFrame\n",
    "    return met_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing/image_preprocessing.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_images(image_folder):\n",
    "    image_paths = sorted(glob.glob(os.path.join(image_folder, '*.jpg')))\n",
    "    images = []\n",
    "    image_timestamps = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        # Extract timestamp from image filename\n",
    "        # Assuming filename format: YYYYMMDDHHMMSS.jpg\n",
    "        filename = os.path.basename(path)\n",
    "        timestamp_str = filename.replace('.jpg', '')\n",
    "        timestamp = pd.to_datetime(timestamp_str, format='%Y%m%d%H%M%S')\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            continue  # Skip if the image is not readable\n",
    "        # Iterates over each image path, reads the image using OpenCV, and resizes it to 128x128 pixels\n",
    "\t    # Normalizes pixel values to the range [0, 1] by dividing by 255\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img = img / 255.0  # Normalize pixel values\n",
    "        images.append(img)\n",
    "        image_timestamps.append(timestamp)\n",
    "\n",
    "    return images, image_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Irradiance</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>image_url</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Wind Dir Sin</th>\n",
       "      <th>Wind Dir Cos</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>Irradiance_5min_ahead</th>\n",
       "      <th>Irradiance_15min_ahead</th>\n",
       "      <th>Irradiance_30min_ahead</th>\n",
       "      <th>Irradiance_60min_ahead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20241116065000</td>\n",
       "      <td>8.16102</td>\n",
       "      <td>0.221854</td>\n",
       "      <td>0.598923</td>\n",
       "      <td>0.311558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-16 06:50:00</td>\n",
       "      <td>-0.761538</td>\n",
       "      <td>0.648120</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.879452</td>\n",
       "      <td>14.6895</td>\n",
       "      <td>31.3017</td>\n",
       "      <td>66.4804</td>\n",
       "      <td>152.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20241116065100</td>\n",
       "      <td>9.39915</td>\n",
       "      <td>0.232479</td>\n",
       "      <td>0.573800</td>\n",
       "      <td>0.369447</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-16 06:51:00</td>\n",
       "      <td>-0.814116</td>\n",
       "      <td>0.580703</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.879452</td>\n",
       "      <td>16.1444</td>\n",
       "      <td>33.2346</td>\n",
       "      <td>69.2944</td>\n",
       "      <td>155.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20241116065200</td>\n",
       "      <td>10.62110</td>\n",
       "      <td>0.241836</td>\n",
       "      <td>0.587707</td>\n",
       "      <td>0.273970</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-16 06:52:00</td>\n",
       "      <td>-0.719340</td>\n",
       "      <td>0.694658</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.879452</td>\n",
       "      <td>17.6113</td>\n",
       "      <td>35.2643</td>\n",
       "      <td>72.1972</td>\n",
       "      <td>158.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20241116065300</td>\n",
       "      <td>11.92040</td>\n",
       "      <td>0.242129</td>\n",
       "      <td>0.595334</td>\n",
       "      <td>0.181508</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-16 06:53:00</td>\n",
       "      <td>-0.846193</td>\n",
       "      <td>0.532876</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.879452</td>\n",
       "      <td>19.0965</td>\n",
       "      <td>37.5257</td>\n",
       "      <td>74.9238</td>\n",
       "      <td>161.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20241116065400</td>\n",
       "      <td>13.26040</td>\n",
       "      <td>0.240667</td>\n",
       "      <td>0.593540</td>\n",
       "      <td>0.176281</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-16 06:54:00</td>\n",
       "      <td>-0.931056</td>\n",
       "      <td>0.364877</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.879452</td>\n",
       "      <td>20.6639</td>\n",
       "      <td>39.6576</td>\n",
       "      <td>77.6095</td>\n",
       "      <td>164.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>20241117081800</td>\n",
       "      <td>238.66300</td>\n",
       "      <td>0.403158</td>\n",
       "      <td>0.557649</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-17 08:18:00</td>\n",
       "      <td>0.705872</td>\n",
       "      <td>-0.708340</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.882192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>20241117081900</td>\n",
       "      <td>241.60100</td>\n",
       "      <td>0.403158</td>\n",
       "      <td>0.537909</td>\n",
       "      <td>0.238794</td>\n",
       "      <td>0.995299</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-17 08:19:00</td>\n",
       "      <td>0.653421</td>\n",
       "      <td>-0.756995</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.882192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>20241117082000</td>\n",
       "      <td>244.37500</td>\n",
       "      <td>0.399162</td>\n",
       "      <td>0.602961</td>\n",
       "      <td>0.294070</td>\n",
       "      <td>0.989500</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-17 08:20:00</td>\n",
       "      <td>0.746638</td>\n",
       "      <td>-0.665230</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.882192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>20241117082100</td>\n",
       "      <td>247.39600</td>\n",
       "      <td>0.397895</td>\n",
       "      <td>0.662180</td>\n",
       "      <td>0.334271</td>\n",
       "      <td>0.988246</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-17 08:21:00</td>\n",
       "      <td>0.721760</td>\n",
       "      <td>-0.692143</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.882192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>20241117082200</td>\n",
       "      <td>250.43200</td>\n",
       "      <td>0.404035</td>\n",
       "      <td>0.596231</td>\n",
       "      <td>0.334271</td>\n",
       "      <td>0.983858</td>\n",
       "      <td>https://solar-tracker-images.s3.us-east-2.amaz...</td>\n",
       "      <td>2024-11-17 08:22:00</td>\n",
       "      <td>0.842452</td>\n",
       "      <td>-0.538771</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.882192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>684 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime  Irradiance  Temperature  Humidity  Wind Speed  Pressure  \\\n",
       "0    20241116065000     8.16102     0.221854  0.598923    0.311558  0.000000   \n",
       "1    20241116065100     9.39915     0.232479  0.573800    0.369447  0.003761   \n",
       "2    20241116065200    10.62110     0.241836  0.587707    0.273970  0.003448   \n",
       "3    20241116065300    11.92040     0.242129  0.595334    0.181508  0.003918   \n",
       "4    20241116065400    13.26040     0.240667  0.593540    0.176281  0.004701   \n",
       "..              ...         ...          ...       ...         ...       ...   \n",
       "679  20241117081800   238.66300     0.403158  0.557649    0.344322  1.000000   \n",
       "680  20241117081900   241.60100     0.403158  0.537909    0.238794  0.995299   \n",
       "681  20241117082000   244.37500     0.399162  0.602961    0.294070  0.989500   \n",
       "682  20241117082100   247.39600     0.397895  0.662180    0.334271  0.988246   \n",
       "683  20241117082200   250.43200     0.404035  0.596231    0.334271  0.983858   \n",
       "\n",
       "                                             image_url           Timestamp  \\\n",
       "0    https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-16 06:50:00   \n",
       "1    https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-16 06:51:00   \n",
       "2    https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-16 06:52:00   \n",
       "3    https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-16 06:53:00   \n",
       "4    https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-16 06:54:00   \n",
       "..                                                 ...                 ...   \n",
       "679  https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-17 08:18:00   \n",
       "680  https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-17 08:19:00   \n",
       "681  https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-17 08:20:00   \n",
       "682  https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-17 08:21:00   \n",
       "683  https://solar-tracker-images.s3.us-east-2.amaz... 2024-11-17 08:22:00   \n",
       "\n",
       "     Wind Dir Sin  Wind Dir Cos      Hour  DayOfYear  Irradiance_5min_ahead  \\\n",
       "0       -0.761538      0.648120  0.260870   0.879452                14.6895   \n",
       "1       -0.814116      0.580703  0.260870   0.879452                16.1444   \n",
       "2       -0.719340      0.694658  0.260870   0.879452                17.6113   \n",
       "3       -0.846193      0.532876  0.260870   0.879452                19.0965   \n",
       "4       -0.931056      0.364877  0.260870   0.879452                20.6639   \n",
       "..            ...           ...       ...        ...                    ...   \n",
       "679      0.705872     -0.708340  0.347826   0.882192                    NaN   \n",
       "680      0.653421     -0.756995  0.347826   0.882192                    NaN   \n",
       "681      0.746638     -0.665230  0.347826   0.882192                    NaN   \n",
       "682      0.721760     -0.692143  0.347826   0.882192                    NaN   \n",
       "683      0.842452     -0.538771  0.347826   0.882192                    NaN   \n",
       "\n",
       "     Irradiance_15min_ahead  Irradiance_30min_ahead  Irradiance_60min_ahead  \n",
       "0                   31.3017                 66.4804                 152.526  \n",
       "1                   33.2346                 69.2944                 155.594  \n",
       "2                   35.2643                 72.1972                 158.274  \n",
       "3                   37.5257                 74.9238                 161.364  \n",
       "4                   39.6576                 77.6095                 164.285  \n",
       "..                      ...                     ...                     ...  \n",
       "679                     NaN                     NaN                     NaN  \n",
       "680                     NaN                     NaN                     NaN  \n",
       "681                     NaN                     NaN                     NaN  \n",
       "682                     NaN                     NaN                     NaN  \n",
       "683                     NaN                     NaN                     NaN  \n",
       "\n",
       "[684 rows x 16 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_data = preprocess_meteorological_data('weather_data.csv')\n",
    "met_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, image_timestamps = preprocess_images('pics')\n",
    "len(image_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data contains 499 records.\n",
      "Testing data contains 125 records.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Align Data with Images\n",
    "def align_data_with_images(met_data, images, image_timestamps):\n",
    "    \"\"\"\n",
    "    Aligns meteorological data with corresponding images based on timestamps.\n",
    "\n",
    "    Parameters:\n",
    "    - met_data: pandas DataFrame containing meteorological data.\n",
    "    - images: list or numpy array of preprocessed images.\n",
    "    - image_timestamps: list or pandas Series of image timestamps.\n",
    "\n",
    "    Returns:\n",
    "    - merged_data: pandas DataFrame containing aligned meteorological data and images.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame for image timestamps\n",
    "    image_df = pd.DataFrame({'Timestamp': image_timestamps, 'Image': images})\n",
    "    image_df['Timestamp'] = pd.to_datetime(image_df['Timestamp'])\n",
    "    \n",
    "    # Ensure meteorological data has datetime objects\n",
    "    met_data['Timestamp'] = pd.to_datetime(met_data['Timestamp'])\n",
    "    \n",
    "    # Merge meteorological data with images using an inner join to keep only matching timestamps\n",
    "    merged_data = pd.merge(met_data, image_df, on='Timestamp', how='inner')\n",
    "    \n",
    "    # Prepare target variables (future irradiance)\n",
    "    target = 'Irradiance'\n",
    "    for minutes in [5, 15, 30, 60]:\n",
    "        merged_data[f'Irradiance_{minutes}min_ahead'] = merged_data[target].shift(-minutes)\n",
    "    \n",
    "    # Drop rows with any remaining missing values (due to shifting)\n",
    "    merged_data.dropna(inplace=True)\n",
    "    \n",
    "    # Reset index after dropping rows\n",
    "    merged_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "merged_data = align_data_with_images(met_data, images, image_timestamps)\n",
    "\n",
    "# Step 3: Split Data into Training and Testing Sets BEFORE Sequence Creation\n",
    "split_ratio = 0.8  # 80% for training, 20% for testing\n",
    "split_index = int(len(merged_data) * split_ratio)\n",
    "\n",
    "# Perform the split\n",
    "train_data = merged_data.iloc[:split_index]\n",
    "test_data = merged_data.iloc[split_index:]\n",
    "\n",
    "print(f\"Training data contains {len(train_data)} records.\")\n",
    "print(f\"Testing data contains {len(test_data)} records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 439 training sequences.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['Image_Input', 'LSTM_Input']. Received: the structure of inputs={'Image_Input': '*', 'LSTM_Input': '*'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - loss: 166790.0938 - mae: 378.7816 - val_loss: 250638.4531 - val_mae: 494.5575 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - loss: 39544.9961 - mae: 166.5748 - val_loss: 163756.1562 - val_mae: 403.7149 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - loss: 24068.4258 - mae: 130.7008 - val_loss: 102439.9688 - val_mae: 317.7763 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - loss: 21915.4785 - mae: 130.7383 - val_loss: 108349.6797 - val_mae: 328.3203 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - loss: 20559.5840 - mae: 119.0342 - val_loss: 79231.0312 - val_mae: 280.2571 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - loss: 69455.0391 - mae: 164.0488 - val_loss: 71176.6641 - val_mae: 263.1262 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 16114.1777 - mae: 108.0850 - val_loss: 35391.6641 - val_mae: 185.9345 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 12047.5596 - mae: 95.9285 - val_loss: 37699.9648 - val_mae: 189.7498 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - loss: 8216.1240 - mae: 71.4271 - val_loss: 12088.4912 - val_mae: 97.7232 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 7674.0444 - mae: 70.1060 - val_loss: 16718.6230 - val_mae: 114.0797 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - loss: 6973.7729 - mae: 66.9379 - val_loss: 11759.6875 - val_mae: 92.1950 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 5735.7378 - mae: 59.5070 - val_loss: 16066.0752 - val_mae: 107.7546 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - loss: 6651.7920 - mae: 65.0601 - val_loss: 8874.5771 - val_mae: 77.0442 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - loss: 6844.9004 - mae: 66.9469 - val_loss: 12664.3115 - val_mae: 94.4199 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - loss: 6329.6948 - mae: 63.9390 - val_loss: 16207.6289 - val_mae: 109.0383 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 5408.4810 - mae: 58.2822 - val_loss: 10733.0459 - val_mae: 85.9429 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 5786.9092 - mae: 60.1748 - val_loss: 13295.5166 - val_mae: 96.9963 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 5396.2227 - mae: 58.7981 - val_loss: 13706.9443 - val_mae: 98.6134 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# training/train_model.py\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from models.hybrid import create_hybrid_model  # Ensure correct import path\n",
    "import pandas as pd\n",
    "\n",
    "def train_hybrid_model(train_data, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Trains the hybrid CNN-LSTM model on the provided training data.\n",
    "\n",
    "    Parameters:\n",
    "    - train_data: pandas DataFrame containing training meteorological data and images.\n",
    "    - sequence_length: Number of past minutes to consider for each sequence.\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained Keras model.\n",
    "    - history: Training history object.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define feature columns\n",
    "    features = [\n",
    "        'Temperature', 'Humidity', 'Pressure', 'Wind Speed',\n",
    "        'Wind Dir Sin', 'Wind Dir Cos', 'Hour', 'DayOfYear'\n",
    "    ]  # Exclude direct current irradiance as a feature\n",
    "\n",
    "    # Extract features and targets\n",
    "    X_num_train, X_img_train, y_train = create_sequences(train_data, sequence_length, features)\n",
    "\n",
    "    print(f\"Created {len(X_num_train)} training sequences.\")\n",
    "\n",
    "    # Create and compile the model\n",
    "    num_features = X_num_train.shape[2]\n",
    "    model = create_hybrid_model(sequence_length, num_features)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "\n",
    "    # Train the model with dictionary inputs\n",
    "    history = model.fit(\n",
    "        {'Image_Input': X_img_train, 'LSTM_Input': X_num_train},\n",
    "        y_train,\n",
    "        validation_split=0.1,  # Further split training data for validation\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def create_sequences(data, seq_length, features):\n",
    "    \"\"\"\n",
    "    Creates input sequences and corresponding targets from the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data.\n",
    "    - seq_length: Length of each input sequence.\n",
    "    - features: List of feature column names.\n",
    "\n",
    "    Returns:\n",
    "    - X_num_seq: Numpy array of numerical feature sequences.\n",
    "    - X_img_seq: Numpy array of image sequences.\n",
    "    - y_seq: Numpy array of target irradiance values.\n",
    "    \"\"\"\n",
    "    X_num_seq, X_img_seq, y_seq = [], [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # Extract numerical features for the sequence\n",
    "        X_num_seq.append(data[features].values[i:i+seq_length])\n",
    "        \n",
    "        # Extract the corresponding image at the last timestamp of the sequence\n",
    "        X_img_seq.append(data['Image'].values[i+seq_length-1])\n",
    "        \n",
    "        # Extract the target irradiance values at the end of the sequence\n",
    "        y_seq.append(data[[f'Irradiance_{minutes}min_ahead' for minutes in [5, 15, 30, 60]]].values[i+seq_length-1])\n",
    "    \n",
    "    return np.array(X_num_seq), np.array(X_img_seq), np.array(y_seq)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 439 training sequences.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['Image_Input', 'LSTM_Input']. Received: the structure of inputs={'Image_Input': '*', 'LSTM_Input': '*'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 169494.0000 - mae: 380.9048 - val_loss: 175893.5469 - val_mae: 363.1328 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - loss: 52095.5117 - mae: 188.7865 - val_loss: 118502.2812 - val_mae: 338.3320 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - loss: 25500.9004 - mae: 139.2729 - val_loss: 102648.1328 - val_mae: 319.5043 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - loss: 22112.6035 - mae: 126.4584 - val_loss: 75646.5312 - val_mae: 273.6306 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - loss: 17687.1602 - mae: 118.6458 - val_loss: 60440.7148 - val_mae: 244.1346 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 14382.2988 - mae: 105.5236 - val_loss: 50610.8906 - val_mae: 222.1486 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - loss: 11719.6133 - mae: 93.6750 - val_loss: 21737.6680 - val_mae: 140.1190 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 8498.2002 - mae: 74.5677 - val_loss: 21385.3398 - val_mae: 135.7560 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 6971.0186 - mae: 65.4887 - val_loss: 15485.3447 - val_mae: 113.3450 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 6442.0146 - mae: 64.3024 - val_loss: 11462.9648 - val_mae: 96.0200 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 5921.3428 - mae: 61.1131 - val_loss: 13613.5566 - val_mae: 103.1060 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 6088.5938 - mae: 62.9231 - val_loss: 12142.4248 - val_mae: 96.2162 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step - loss: 5784.3608 - mae: 60.9094 - val_loss: 8878.7354 - val_mae: 79.6608 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - loss: 7552.1016 - mae: 70.9361 - val_loss: 16895.9668 - val_mae: 115.1182 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - loss: 6140.0449 - mae: 63.0472 - val_loss: 11653.2432 - val_mae: 92.4836 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - loss: 6901.5283 - mae: 66.1931 - val_loss: 11492.5156 - val_mae: 92.1116 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step - loss: 5889.5166 - mae: 61.3294 - val_loss: 12588.7979 - val_mae: 96.6093 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - loss: 5974.8906 - mae: 60.6583 - val_loss: 10240.3193 - val_mae: 86.1542 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the Model\n",
    "model, history = train_hybrid_model(train_data, sequence_length=60)\n",
    "\n",
    "# Save the model\n",
    "model.save('trainedModels/test.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation/evaluate_model.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def evaluate_model(model, test_data, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Evaluates the regression model on the provided test_data.\n",
    "    Saves evaluation plots in a uniquely named subfolder within 'evaluation_plots'.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained Keras model.\n",
    "    - test_data: pandas DataFrame containing testing meteorological data and images.\n",
    "    - sequence_length: Number of past minutes to consider for each sequence.\n",
    "    \"\"\"\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 1. Setup Directory for Saving Plots\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Define the base directory for evaluation plots\n",
    "    base_dir = 'evaluation_plots'\n",
    "    \n",
    "    # Create the base directory if it doesn't exist\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "        print(f\"Created base directory for evaluation plots at '{base_dir}'.\")\n",
    "    \n",
    "    # Generate a unique subfolder name using the current timestamp\n",
    "    run_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    run_folder = os.path.join(base_dir, f'run_{run_timestamp}')\n",
    "    \n",
    "    # Create the subfolder\n",
    "    os.makedirs(run_folder, exist_ok=True)\n",
    "    print(f\"Created run-specific directory at '{run_folder}'.\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 2. Prepare Data for Evaluation\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Define feature columns\n",
    "    features = [\n",
    "        'Temperature', 'Humidity', 'Pressure', 'Wind Speed',\n",
    "        'Wind Dir Sin', 'Wind Dir Cos', 'Hour', 'DayOfYear'\n",
    "    ]  # Exclude direct current irradiance as a feature\n",
    "\n",
    "    # Extract features and targets\n",
    "    X_num = test_data[features].values\n",
    "    y = test_data[[f'Irradiance_{minutes}min_ahead' for minutes in [5, 15, 30, 60]]].values\n",
    "    X_img = np.array(test_data['Image'].tolist())\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3. Create Sequences\n",
    "    # -----------------------------\n",
    "    \n",
    "    def create_sequences(X_num, X_img, y, seq_length):\n",
    "        \"\"\"\n",
    "        Creates input sequences for the model.\n",
    "        \n",
    "        Parameters:\n",
    "        - X_num: Numpy array of numerical features.\n",
    "        - X_img: Numpy array of images.\n",
    "        - y: Numpy array of target variables.\n",
    "        - seq_length: Length of the input sequences.\n",
    "        \n",
    "        Returns:\n",
    "        - Tuple of Numpy arrays: (X_num_seq, X_img_seq, y_seq)\n",
    "        \"\"\"\n",
    "        X_num_seq, X_img_seq, y_seq = [], [], []\n",
    "        for i in range(len(X_num) - seq_length):\n",
    "            X_num_seq.append(X_num[i:i+seq_length])\n",
    "            X_img_seq.append(X_img[i+seq_length-1])  # Use image at the last timestamp\n",
    "            y_seq.append(y[i+seq_length-1])\n",
    "        return np.array(X_num_seq), np.array(X_img_seq), np.array(y_seq)\n",
    "\n",
    "    # Generate sequences from test data\n",
    "    X_num_seq, X_img_seq, y_seq = create_sequences(X_num, X_img, y, sequence_length)\n",
    "    print(f\"Created {len(X_num_seq)} sequences for evaluation.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4. No Further Splitting Needed\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Since test_data is already separate, no need to split again\n",
    "    X_num_test = X_num_seq\n",
    "    X_img_test = X_img_seq\n",
    "    y_test = y_seq\n",
    "    \n",
    "    print(f\"Evaluation split: {len(X_num_test)} samples.\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 5. Make Predictions\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Generate predictions using the trained model\n",
    "    y_pred = model.predict({'Image_Input': X_img_test, 'LSTM_Input': X_num_test})\n",
    "    print(\"Generated predictions for the test set.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. Calculate and Save Metrics and Plots\n",
    "    # -----------------------------\n",
    "    \n",
    "    horizons = [5, 15, 30, 60]  # Prediction horizons in minutes\n",
    "    \n",
    "    # Initialize a text file to save metrics\n",
    "    metrics_file = os.path.join(run_folder, 'metrics.txt')\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(\"Evaluation Metrics:\\n\")\n",
    "        f.write(\"===================\\n\\n\")\n",
    "    \n",
    "    for i, minutes in enumerate(horizons):\n",
    "        # Calculate metrics for each horizon\n",
    "        rmse = np.sqrt(mean_squared_error(y_test[:, i], y_pred[:, i]))\n",
    "        mae = mean_absolute_error(y_test[:, i], y_pred[:, i])\n",
    "        r2 = r2_score(y_test[:, i], y_pred[:, i])\n",
    "        metric_str = f\"{minutes}-Minute Ahead Prediction - RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.2f}\"\n",
    "        print(metric_str)\n",
    "        \n",
    "        # Append metrics to the text file\n",
    "        with open(metrics_file, 'a') as f:\n",
    "            f.write(metric_str + \"\\n\")\n",
    "        \n",
    "        # Plot Actual vs Predicted\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(y_test[:, i], label='Actual', alpha=0.7)\n",
    "        plt.plot(y_pred[:, i], label='Predicted', alpha=0.7)\n",
    "        plt.title(f'{minutes}-Minute Ahead Prediction')\n",
    "        plt.xlabel('Samples')\n",
    "        plt.ylabel('Irradiance (W/m²)')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_filename = f'{minutes}_min_ahead_prediction.png'\n",
    "        plot_path = os.path.join(run_folder, plot_filename)\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot: {plot_path}\")\n",
    "        \n",
    "        # Plot Scatter of Actual vs Predicted\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(y_test[:, i], y_pred[:, i], alpha=0.5)\n",
    "        plt.plot([y_test[:, i].min(), y_test[:, i].max()],\n",
    "                 [y_test[:, i].min(), y_test[:, i].max()],\n",
    "                 'r--', lw=2)\n",
    "        plt.title(f'Actual vs Predicted Irradiance ({minutes} min Ahead)')\n",
    "        plt.xlabel('Actual Irradiance (W/m²)')\n",
    "        plt.ylabel('Predicted Irradiance (W/m²)')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the scatter plot\n",
    "        scatter_filename = f'actual_vs_predicted_{minutes}_min_ahead.png'\n",
    "        scatter_path = os.path.join(run_folder, scatter_filename)\n",
    "        plt.savefig(scatter_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved scatter plot: {scatter_path}\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 7. Calculate and Save Overall Metrics and Plots\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Calculate overall performance metrics across all horizons\n",
    "    overall_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    overall_mae = mean_absolute_error(y_test, y_pred)\n",
    "    overall_r2 = r2_score(y_test, y_pred)\n",
    "    overall_metric_str = f\"Overall Performance - RMSE: {overall_rmse:.2f}, MAE: {overall_mae:.2f}, R²: {overall_r2:.2f}\"\n",
    "    print(overall_metric_str)\n",
    "    \n",
    "    # Append overall metrics to the text file\n",
    "    with open(metrics_file, 'a') as f:\n",
    "        f.write(\"\\n\" + overall_metric_str + \"\\n\")\n",
    "    \n",
    "    # Plot Overall Actual vs Predicted\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()],\n",
    "             [y_test.min(), y_test.max()],\n",
    "             'r--', lw=2)\n",
    "    plt.title('Actual vs Predicted Irradiance (Overall)')\n",
    "    plt.xlabel('Actual Irradiance (W/m²)')\n",
    "    plt.ylabel('Predicted Irradiance (W/m²)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the overall scatter plot\n",
    "    overall_scatter_filename = 'actual_vs_predicted_overall.png'\n",
    "    overall_scatter_path = os.path.join(run_folder, overall_scatter_filename)\n",
    "    plt.savefig(overall_scatter_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved overall scatter plot: {overall_scatter_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created run-specific directory at 'evaluation_plots/run_20241119_220812'.\n",
      "Created 65 sequences for evaluation.\n",
      "Evaluation split: 65 samples.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Generated predictions for the test set.\n",
      "5-Minute Ahead Prediction - RMSE: 165.72, MAE: 162.16, R²: -46.01\n",
      "Saved plot: evaluation_plots/run_20241119_220812/5_min_ahead_prediction.png\n",
      "Saved scatter plot: evaluation_plots/run_20241119_220812/actual_vs_predicted_5_min_ahead.png\n",
      "15-Minute Ahead Prediction - RMSE: 129.65, MAE: 123.52, R²: -13.16\n",
      "Saved plot: evaluation_plots/run_20241119_220812/15_min_ahead_prediction.png\n",
      "Saved scatter plot: evaluation_plots/run_20241119_220812/actual_vs_predicted_15_min_ahead.png\n",
      "30-Minute Ahead Prediction - RMSE: 127.72, MAE: 118.12, R²: -6.35\n",
      "Saved plot: evaluation_plots/run_20241119_220812/30_min_ahead_prediction.png\n",
      "Saved scatter plot: evaluation_plots/run_20241119_220812/actual_vs_predicted_30_min_ahead.png\n",
      "60-Minute Ahead Prediction - RMSE: 57.88, MAE: 47.50, R²: -0.08\n",
      "Saved plot: evaluation_plots/run_20241119_220812/60_min_ahead_prediction.png\n",
      "Saved scatter plot: evaluation_plots/run_20241119_220812/actual_vs_predicted_60_min_ahead.png\n",
      "Overall Performance - RMSE: 126.43, MAE: 112.82, R²: -16.40\n",
      "Saved overall scatter plot: evaluation_plots/run_20241119_220812/actual_vs_predicted_overall.png\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_data, sequence_length=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

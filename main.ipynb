{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /scratch/user/eanazir/.local/lib/python3.10/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: six>=1.5 in /sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing/data_preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "def preprocess_meteorological_data(file_path):\n",
    "    # Load data\n",
    "    met_data = pd.read_csv(file_path)\n",
    "\n",
    "    # Combine DATE and MST into a single datetime column\n",
    "    # met_data['Timestamp'] = pd.to_datetime(met_data['DATE'] + ' ' + met_data['MST'])\n",
    "    # Combine DATE and MST into a single datetime column\n",
    "    met_data['Timestamp'] = pd.to_datetime(met_data['datetime'].astype(str), format='%Y%m%d%H%M%S')\n",
    "\n",
    "    # Sort data by Timestamp\n",
    "    met_data.sort_values('Timestamp', inplace=True)\n",
    "\n",
    "    # Handle missing values in input features using KNN imputation\n",
    "    input_features = [\n",
    "        'Tower Dry Bulb Temp [deg C]', 'Tower RH [%]', 'Station Pressure [mBar]',\n",
    "        'Avg Wind Speed @ 6ft [m/s]', 'Avg Wind Direction @ 6ft [deg from N]'\n",
    "    ]\n",
    "\n",
    "    # Initialize KNN imputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "    # Fit and transform the input features\n",
    "    met_data_imputed = imputer.fit_transform(met_data[input_features])\n",
    "\n",
    "    # Update the DataFrame with imputed values\n",
    "    met_data[input_features] = met_data_imputed\n",
    "\n",
    "    # Handle missing values in the target variable separately\n",
    "    target_variable = 'Global CMP22 (vent/cor) [W/m^2]'\n",
    "\n",
    "    # Optionally interpolate missing target values\n",
    "    # met_data[target_variable].interpolate(method='time', inplace=True)\n",
    "    \n",
    "    # Option 2: Drop rows with missing target values (uncomment if preferred)\n",
    "    met_data.dropna(subset=[target_variable], inplace=True)\n",
    "\n",
    "    # Rename columns for simplicity\n",
    "    met_data.rename(columns={\n",
    "        'Tower Dry Bulb Temp [deg C]': 'Temperature',\n",
    "        'Tower RH [%]': 'Humidity',\n",
    "        'Station Pressure [mBar]': 'Pressure',\n",
    "        'Avg Wind Speed @ 6ft [m/s]': 'Wind Speed',\n",
    "        'Avg Wind Direction @ 6ft [deg from N]': 'Wind Direction',\n",
    "        'Global CMP22 (vent/cor) [W/m^2]': 'Irradiance'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Feature scaling for input features\n",
    "    scaler = MinMaxScaler()\n",
    "    met_data[['Temperature', 'Humidity', 'Pressure', 'Wind Speed']] = scaler.fit_transform(\n",
    "        met_data[['Temperature', 'Humidity', 'Pressure', 'Wind Speed']]\n",
    "    )\n",
    "    joblib.dump(scaler, 'scaler_y.pkl')\n",
    "\n",
    "    # Wind Direction encoding (convert degrees to sine and cosine components)\n",
    "    met_data['Wind Dir Sin'] = np.sin(np.deg2rad(met_data['Wind Direction']))\n",
    "    met_data['Wind Dir Cos'] = np.cos(np.deg2rad(met_data['Wind Direction']))\n",
    "    met_data.drop('Wind Direction', axis=1, inplace=True)\n",
    "\n",
    "    # Temporal features\n",
    "    met_data['Hour'] = met_data['Timestamp'].dt.hour / 23.0  # Normalize Hour\n",
    "    met_data['DayOfYear'] = met_data['Timestamp'].dt.dayofyear / 365.0  # Normalize DayOfYear\n",
    "\n",
    "    # Prepare target variables (future irradiance)\n",
    "    target = 'Irradiance'\n",
    "    for minutes in [5, 15, 30, 60]:\n",
    "        met_data[f'Irradiance_{minutes}min_ahead'] = met_data[target].shift(-minutes)\n",
    "\n",
    "    # **Removed the line that drops rows with NaN values after shifting**\n",
    "    # We will handle dropping NaN values after merging with images\n",
    "    # met_data.dropna(inplace=True)\n",
    "\n",
    "    # Reset index and return the processed DataFrame\n",
    "    return met_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing/image_preprocessing.py\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_images(image_folder):\n",
    "    image_paths = sorted(glob.glob(os.path.join(image_folder, '*.jpg')))\n",
    "    images = []\n",
    "    image_timestamps = []\n",
    "\n",
    "    for path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "        # Extract timestamp from image filename\n",
    "        # Assuming filename format: YYYYMMDDHHMMSS.jpg\n",
    "        filename = os.path.basename(path)\n",
    "        timestamp_str = filename.replace('.jpg', '')\n",
    "        timestamp = pd.to_datetime(timestamp_str, format='%Y%m%d%H%M%S')\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            continue  # Skip if the image is not readable\n",
    "        # Iterates over each image path, reads the image using OpenCV, and resizes it to 128x128 pixels\n",
    "        # Normalizes pixel values to the range [0, 1] by dividing by 255\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img = img / 255.0  # Normalize pixel values\n",
    "        images.append(img)\n",
    "        image_timestamps.append(timestamp)\n",
    "\n",
    "    return images, image_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Irradiance</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Wind Dir Sin</th>\n",
       "      <th>Wind Dir Cos</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>Irradiance_5min_ahead</th>\n",
       "      <th>Irradiance_15min_ahead</th>\n",
       "      <th>Irradiance_30min_ahead</th>\n",
       "      <th>Irradiance_60min_ahead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230101065000</td>\n",
       "      <td>-0.847312</td>\n",
       "      <td>0.577610</td>\n",
       "      <td>0.536853</td>\n",
       "      <td>0.110047</td>\n",
       "      <td>0.184172</td>\n",
       "      <td>2023-01-01 06:50:00</td>\n",
       "      <td>-0.987688</td>\n",
       "      <td>-0.156434</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>-0.718261</td>\n",
       "      <td>-0.419715</td>\n",
       "      <td>1.97398</td>\n",
       "      <td>26.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230101065100</td>\n",
       "      <td>-0.827263</td>\n",
       "      <td>0.577795</td>\n",
       "      <td>0.540062</td>\n",
       "      <td>0.125623</td>\n",
       "      <td>0.184632</td>\n",
       "      <td>2023-01-01 06:51:00</td>\n",
       "      <td>-0.999976</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>-0.708250</td>\n",
       "      <td>-0.333484</td>\n",
       "      <td>2.17521</td>\n",
       "      <td>27.4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230101065200</td>\n",
       "      <td>-0.821106</td>\n",
       "      <td>0.577637</td>\n",
       "      <td>0.542165</td>\n",
       "      <td>0.124611</td>\n",
       "      <td>0.185540</td>\n",
       "      <td>2023-01-01 06:52:00</td>\n",
       "      <td>-0.998027</td>\n",
       "      <td>-0.062791</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>-0.662647</td>\n",
       "      <td>-0.257296</td>\n",
       "      <td>2.46600</td>\n",
       "      <td>28.8680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230101065300</td>\n",
       "      <td>-0.789932</td>\n",
       "      <td>0.577663</td>\n",
       "      <td>0.544046</td>\n",
       "      <td>0.112928</td>\n",
       "      <td>0.185629</td>\n",
       "      <td>2023-01-01 06:53:00</td>\n",
       "      <td>-0.999328</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>-0.594409</td>\n",
       "      <td>-0.166430</td>\n",
       "      <td>2.73742</td>\n",
       "      <td>30.3134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230101065400</td>\n",
       "      <td>-0.734090</td>\n",
       "      <td>0.577346</td>\n",
       "      <td>0.545374</td>\n",
       "      <td>0.123676</td>\n",
       "      <td>0.185092</td>\n",
       "      <td>2023-01-01 06:54:00</td>\n",
       "      <td>-0.999328</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>-0.542234</td>\n",
       "      <td>-0.025133</td>\n",
       "      <td>3.04919</td>\n",
       "      <td>31.7266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19458</th>\n",
       "      <td>20230130174600</td>\n",
       "      <td>-0.444423</td>\n",
       "      <td>0.154904</td>\n",
       "      <td>0.800797</td>\n",
       "      <td>0.139252</td>\n",
       "      <td>0.220520</td>\n",
       "      <td>2023-01-30 17:46:00</td>\n",
       "      <td>0.956509</td>\n",
       "      <td>0.291704</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19459</th>\n",
       "      <td>20230130174700</td>\n",
       "      <td>-0.432117</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>0.801903</td>\n",
       "      <td>0.134346</td>\n",
       "      <td>0.220687</td>\n",
       "      <td>2023-01-30 17:47:00</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.583825</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19460</th>\n",
       "      <td>20230130174800</td>\n",
       "      <td>-0.451800</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>0.800797</td>\n",
       "      <td>0.113941</td>\n",
       "      <td>0.221415</td>\n",
       "      <td>2023-01-30 17:48:00</td>\n",
       "      <td>0.956356</td>\n",
       "      <td>0.292205</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19461</th>\n",
       "      <td>20230130174900</td>\n",
       "      <td>-0.482391</td>\n",
       "      <td>0.154110</td>\n",
       "      <td>0.801903</td>\n",
       "      <td>0.113941</td>\n",
       "      <td>0.222016</td>\n",
       "      <td>2023-01-30 17:49:00</td>\n",
       "      <td>0.924280</td>\n",
       "      <td>0.381716</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19462</th>\n",
       "      <td>20230130175000</td>\n",
       "      <td>-0.510046</td>\n",
       "      <td>0.154110</td>\n",
       "      <td>0.800797</td>\n",
       "      <td>0.120717</td>\n",
       "      <td>0.221965</td>\n",
       "      <td>2023-01-30 17:50:00</td>\n",
       "      <td>0.900774</td>\n",
       "      <td>0.434288</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19463 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  Irradiance  Temperature  Humidity  Wind Speed  \\\n",
       "0      20230101065000   -0.847312     0.577610  0.536853    0.110047   \n",
       "1      20230101065100   -0.827263     0.577795  0.540062    0.125623   \n",
       "2      20230101065200   -0.821106     0.577637  0.542165    0.124611   \n",
       "3      20230101065300   -0.789932     0.577663  0.544046    0.112928   \n",
       "4      20230101065400   -0.734090     0.577346  0.545374    0.123676   \n",
       "...               ...         ...          ...       ...         ...   \n",
       "19458  20230130174600   -0.444423     0.154904  0.800797    0.139252   \n",
       "19459  20230130174700   -0.432117     0.154639  0.801903    0.134346   \n",
       "19460  20230130174800   -0.451800     0.154639  0.800797    0.113941   \n",
       "19461  20230130174900   -0.482391     0.154110  0.801903    0.113941   \n",
       "19462  20230130175000   -0.510046     0.154110  0.800797    0.120717   \n",
       "\n",
       "       Pressure           Timestamp  Wind Dir Sin  Wind Dir Cos     Hour  \\\n",
       "0      0.184172 2023-01-01 06:50:00     -0.987688     -0.156434  0.26087   \n",
       "1      0.184632 2023-01-01 06:51:00     -0.999976      0.006981  0.26087   \n",
       "2      0.185540 2023-01-01 06:52:00     -0.998027     -0.062791  0.26087   \n",
       "3      0.185629 2023-01-01 06:53:00     -0.999328      0.036644  0.26087   \n",
       "4      0.185092 2023-01-01 06:54:00     -0.999328      0.036644  0.26087   \n",
       "...         ...                 ...           ...           ...      ...   \n",
       "19458  0.220520 2023-01-30 17:46:00      0.956509      0.291704  0.73913   \n",
       "19459  0.220687 2023-01-30 17:47:00      0.811880      0.583825  0.73913   \n",
       "19460  0.221415 2023-01-30 17:48:00      0.956356      0.292205  0.73913   \n",
       "19461  0.222016 2023-01-30 17:49:00      0.924280      0.381716  0.73913   \n",
       "19462  0.221965 2023-01-30 17:50:00      0.900774      0.434288  0.73913   \n",
       "\n",
       "       DayOfYear  Irradiance_5min_ahead  Irradiance_15min_ahead  \\\n",
       "0       0.002740              -0.718261               -0.419715   \n",
       "1       0.002740              -0.708250               -0.333484   \n",
       "2       0.002740              -0.662647               -0.257296   \n",
       "3       0.002740              -0.594409               -0.166430   \n",
       "4       0.002740              -0.542234               -0.025133   \n",
       "...          ...                    ...                     ...   \n",
       "19458   0.082192                    NaN                     NaN   \n",
       "19459   0.082192                    NaN                     NaN   \n",
       "19460   0.082192                    NaN                     NaN   \n",
       "19461   0.082192                    NaN                     NaN   \n",
       "19462   0.082192                    NaN                     NaN   \n",
       "\n",
       "       Irradiance_30min_ahead  Irradiance_60min_ahead  \n",
       "0                     1.97398                 26.0810  \n",
       "1                     2.17521                 27.4360  \n",
       "2                     2.46600                 28.8680  \n",
       "3                     2.73742                 30.3134  \n",
       "4                     3.04919                 31.7266  \n",
       "...                       ...                     ...  \n",
       "19458                     NaN                     NaN  \n",
       "19459                     NaN                     NaN  \n",
       "19460                     NaN                     NaN  \n",
       "19461                     NaN                     NaN  \n",
       "19462                     NaN                     NaN  \n",
       "\n",
       "[19463 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_data = preprocess_meteorological_data('data/combined_data.csv')\n",
    "met_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, image_timestamps = preprocess_images('/data/training_images/')\n",
    "# image_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/train_model.py\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from models.hybrid import create_hybrid_model\n",
    "import pandas as pd\n",
    "\n",
    "def train_hybrid_model(met_data, images, image_timestamps):\n",
    "    # Prepare data\n",
    "    sequence_length = 60  # Number of past minutes to consider\n",
    "    features = ['Temperature', 'Humidity', 'Pressure', 'Wind Speed', 'Wind Dir Sin', 'Wind Dir Cos',\n",
    "                'Hour', 'DayOfYear']\n",
    "\n",
    "    # Align images with meteorological data\n",
    "    merged_data = align_data_with_images(met_data, images, image_timestamps)\n",
    "\n",
    "    # Extract features and targets\n",
    "    X_num = merged_data[features].values\n",
    "    y = merged_data[[f'Irradiance_{minutes}min_ahead' for minutes in [5, 15, 30, 60]]].values\n",
    "    X_img = np.array(merged_data['Image'].tolist())\n",
    "\n",
    "    # Create sequences\n",
    "    def create_sequences(X_num, X_img, y, seq_length):\n",
    "        X_num_seq, X_img_seq, y_seq = [], [], []\n",
    "        for i in range(len(X_num) - seq_length):\n",
    "            X_num_seq.append(X_num[i:i+seq_length])\n",
    "            X_img_seq.append(X_img[i+seq_length-1])  # Use image at last timestamp\n",
    "            y_seq.append(y[i+seq_length-1])\n",
    "        return np.array(X_num_seq), np.array(X_img_seq), np.array(y_seq)\n",
    "\n",
    "    X_num_seq, X_img_seq, y_seq = create_sequences(X_num, X_img, y, sequence_length)\n",
    "\n",
    "    # Train-test split\n",
    "    split_index = int(0.8 * len(X_num_seq))\n",
    "    X_num_train, X_num_test = X_num_seq[:split_index], X_num_seq[split_index:]\n",
    "    X_img_train, X_img_test = X_img_seq[:split_index], X_img_seq[split_index:]\n",
    "    y_train, y_test = y_seq[:split_index], y_seq[split_index:]\n",
    "\n",
    "    # Create model\n",
    "    num_features = X_num_train.shape[2]\n",
    "    model = create_hybrid_model(sequence_length, num_features)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        [X_img_train, X_num_train],\n",
    "        y_train,\n",
    "        validation_data=([X_img_test, X_num_test], y_test),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    return model, history, merged_data\n",
    "\n",
    "def align_data_with_images(met_data, images, image_timestamps):\n",
    "    # Create a DataFrame for image timestamps\n",
    "    image_df = pd.DataFrame({'Timestamp': image_timestamps, 'Image': images})\n",
    "    image_df['Timestamp'] = pd.to_datetime(image_df['Timestamp'])\n",
    "\n",
    "    # Merge meteorological data with images using an inner join\n",
    "    met_data['Timestamp'] = pd.to_datetime(met_data['Timestamp'])\n",
    "    merged_data = pd.merge(met_data, image_df, on='Timestamp', how='inner')\n",
    "\n",
    "    # Prepare target variables (future irradiance)\n",
    "    target = 'Irradiance'\n",
    "    for minutes in [5, 15, 30, 60]:\n",
    "        merged_data[f'Irradiance_{minutes}min_ahead'] = merged_data[target].shift(-minutes)\n",
    "\n",
    "    # Drop rows with any remaining missing values (after shifting)\n",
    "    merged_data.dropna(inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    merged_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['Image_Input', 'LSTM_Input']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 51387.0742 - mae: 177.9589 - val_loss: 34245.9961 - val_mae: 153.7390 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - loss: 29531.3281 - mae: 143.8452 - val_loss: 31420.1367 - val_mae: 149.2367 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 26398.3242 - mae: 136.4072 - val_loss: 22572.0078 - val_mae: 123.4668 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - loss: 17380.7734 - mae: 103.8256 - val_loss: 20566.5664 - val_mae: 114.3433 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - loss: 15953.9658 - mae: 98.9433 - val_loss: 16924.3262 - val_mae: 103.2513 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 14833.2129 - mae: 92.6789 - val_loss: 20342.1211 - val_mae: 111.1444 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 14472.0195 - mae: 91.6104 - val_loss: 15115.8936 - val_mae: 97.2423 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - loss: 13034.3740 - mae: 85.7294 - val_loss: 18818.3828 - val_mae: 106.5329 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - loss: 15012.1992 - mae: 92.7076 - val_loss: 16785.3105 - val_mae: 101.3512 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - loss: 17722.9863 - mae: 85.0822 - val_loss: 24308.4316 - val_mae: 117.5233 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - loss: 16919.9375 - mae: 98.2391 - val_loss: 16688.7656 - val_mae: 99.6640 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - loss: 12077.9736 - mae: 81.6910 - val_loss: 14727.5684 - val_mae: 95.8128 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - loss: 12036.3623 - mae: 81.1537 - val_loss: 14692.6904 - val_mae: 95.5195 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 12099.3086 - mae: 82.0222 - val_loss: 15695.3193 - val_mae: 98.2070 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - loss: 11267.1992 - mae: 79.1236 - val_loss: 14881.0938 - val_mae: 95.3024 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - loss: 12041.6055 - mae: 81.1879 - val_loss: 15708.3037 - val_mae: 97.9812 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - loss: 10927.8848 - mae: 76.9738 - val_loss: 15477.1729 - val_mae: 97.1551 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 154ms/step - loss: 10932.9590 - mae: 77.0860 - val_loss: 15829.1963 - val_mae: 98.1016 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model, history, merged_data = train_hybrid_model(met_data, images, image_timestamps)\n",
    "\n",
    "# Save the model\n",
    "model.save('trainedModels/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation/evaluate_model.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def evaluate_model(model, merged_data):\n",
    "    \"\"\"\n",
    "    Evaluates the regression model on the provided merged_data.\n",
    "    Saves evaluation plots in a uniquely named subfolder within 'evaluation_plots'.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained Keras model.\n",
    "    - merged_data: pandas DataFrame containing meteorological data and associated images.\n",
    "    \"\"\"\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 1. Setup Directory for Saving Plots\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Define the base directory for evaluation plots\n",
    "    base_dir = 'evaluation_plots'\n",
    "    \n",
    "    # Create the base directory if it doesn't exist\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "        print(f\"Created base directory for evaluation plots at '{base_dir}'.\")\n",
    "    \n",
    "    # Generate a unique subfolder name using the current timestamp\n",
    "    run_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    run_folder = os.path.join(base_dir, f'run_{run_timestamp}')\n",
    "    \n",
    "    # Create the subfolder\n",
    "    os.makedirs(run_folder, exist_ok=True)\n",
    "    print(f\"Created run-specific directory at '{run_folder}'.\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 2. Prepare Data for Evaluation\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Define the sequence length and feature columns\n",
    "    sequence_length = 60\n",
    "    features = [\n",
    "        'Temperature', 'Humidity', 'Pressure', 'Wind Speed',\n",
    "        'Wind Dir Sin', 'Wind Dir Cos', 'Hour', 'DayOfYear'\n",
    "    ]  # Exclude direct current irradiance as a feature\n",
    "\n",
    "    # Extract feature values and target variables\n",
    "    X_num = merged_data[features].values\n",
    "    y = merged_data[[f'Irradiance_{minutes}min_ahead' for minutes in [5, 15, 30, 60]]].values\n",
    "    X_img = np.array(merged_data['Image'].tolist())\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3. Create Sequences\n",
    "    # -----------------------------\n",
    "    \n",
    "    def create_sequences(X_num, X_img, y, seq_length):\n",
    "        \"\"\"\n",
    "        Creates input sequences for the model.\n",
    "        \n",
    "        Parameters:\n",
    "        - X_num: Numpy array of numerical features.\n",
    "        - X_img: Numpy array of images.\n",
    "        - y: Numpy array of target variables.\n",
    "        - seq_length: Length of the input sequences.\n",
    "        \n",
    "        Returns:\n",
    "        - Tuple of Numpy arrays: (X_num_seq, X_img_seq, y_seq)\n",
    "        \"\"\"\n",
    "        X_num_seq, X_img_seq, y_seq = [], [], []\n",
    "        for i in range(len(X_num) - seq_length):\n",
    "            X_num_seq.append(X_num[i:i+seq_length])\n",
    "            X_img_seq.append(X_img[i+seq_length-1])  # Use image at the last timestamp\n",
    "            y_seq.append(y[i+seq_length-1])\n",
    "        return np.array(X_num_seq), np.array(X_img_seq), np.array(y_seq)\n",
    "\n",
    "    # Generate sequences\n",
    "    X_num_seq, X_img_seq, y_seq = create_sequences(X_num, X_img, y, sequence_length)\n",
    "    print(f\"Created {len(X_num_seq)} sequences for evaluation.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 4. Split Data into Test Set\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Define the split index for the last 20% as the test set\n",
    "    split_index = int(0.8 * len(X_num_seq))\n",
    "    \n",
    "    # Split the data\n",
    "    X_num_test = X_num_seq[split_index:]\n",
    "    X_img_test = X_img_seq[split_index:]\n",
    "    y_test = y_seq[split_index:]\n",
    "    \n",
    "    print(f\"Evaluation split: {len(X_num_test)} samples.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 5. Make Predictions\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Generate predictions using the trained model\n",
    "    y_pred = model.predict([X_img_test, X_num_test])\n",
    "    print(\"Generated predictions for the test set.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 6. Calculate and Save Metrics and Plots\n",
    "    # -----------------------------\n",
    "    \n",
    "    horizons = [5, 15, 30, 60]  # Prediction horizons in minutes\n",
    "    \n",
    "    # Initialize a text file to save metrics\n",
    "    metrics_file = os.path.join(run_folder, 'metrics.txt')\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(\"Evaluation Metrics:\\n\")\n",
    "        f.write(\"===================\\n\\n\")\n",
    "    \n",
    "    for i, minutes in enumerate(horizons):\n",
    "        # Calculate metrics for each horizon\n",
    "        rmse = np.sqrt(mean_squared_error(y_test[:, i], y_pred[:, i]))\n",
    "        mae = mean_absolute_error(y_test[:, i], y_pred[:, i])\n",
    "        r2 = r2_score(y_test[:, i], y_pred[:, i])\n",
    "        metric_str = f\"{minutes}-Minute Ahead Prediction - RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.2f}\"\n",
    "        print(metric_str)\n",
    "        \n",
    "        # Append metrics to the text file\n",
    "        with open(metrics_file, 'a') as f:\n",
    "            f.write(metric_str + \"\\n\")\n",
    "        \n",
    "        # Plot Actual vs Predicted\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(y_test[:, i], label='Actual', alpha=0.7)\n",
    "        plt.plot(y_pred[:, i], label='Predicted', alpha=0.7)\n",
    "        plt.title(f'{minutes}-Minute Ahead Prediction')\n",
    "        plt.xlabel('Samples')\n",
    "        plt.ylabel('Irradiance (W/m²)')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_filename = f'{minutes}_min_ahead_prediction.png'\n",
    "        plot_path = os.path.join(run_folder, plot_filename)\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved plot: {plot_path}\")\n",
    "        \n",
    "        # Plot Scatter of Actual vs Predicted\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.scatter(y_test[:, i], y_pred[:, i], alpha=0.5)\n",
    "        plt.plot([y_test[:, i].min(), y_test[:, i].max()],\n",
    "                 [y_test[:, i].min(), y_test[:, i].max()],\n",
    "                 'r--', lw=2)\n",
    "        plt.title(f'Actual vs Predicted Irradiance ({minutes} min Ahead)')\n",
    "        plt.xlabel('Actual Irradiance (W/m²)')\n",
    "        plt.ylabel('Predicted Irradiance (W/m²)')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the scatter plot\n",
    "        scatter_filename = f'actual_vs_predicted_{minutes}_min_ahead.png'\n",
    "        scatter_path = os.path.join(run_folder, scatter_filename)\n",
    "        plt.savefig(scatter_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved scatter plot: {scatter_path}\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 7. Calculate and Save Overall Metrics and Plots\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Calculate overall performance metrics across all horizons\n",
    "    overall_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    overall_mae = mean_absolute_error(y_test, y_pred)\n",
    "    overall_r2 = r2_score(y_test, y_pred)\n",
    "    overall_metric_str = f\"Overall Performance - RMSE: {overall_rmse:.2f}, MAE: {overall_mae:.2f}, R²: {overall_r2:.2f}\"\n",
    "    print(overall_metric_str)\n",
    "    \n",
    "    # Append overall metrics to the text file\n",
    "    with open(metrics_file, 'a') as f:\n",
    "        f.write(\"\\n\" + overall_metric_str + \"\\n\")\n",
    "    \n",
    "    # Plot Overall Actual vs Predicted\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()],\n",
    "             [y_test.min(), y_test.max()],\n",
    "             'r--', lw=2)\n",
    "    plt.title('Actual vs Predicted Irradiance (Overall)')\n",
    "    plt.xlabel('Actual Irradiance (W/m²)')\n",
    "    plt.ylabel('Predicted Irradiance (W/m²)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the overall scatter plot\n",
    "    overall_scatter_filename = 'actual_vs_predicted_overall.png'\n",
    "    overall_scatter_path = os.path.join(run_folder, overall_scatter_filename)\n",
    "    plt.savefig(overall_scatter_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved overall scatter plot: {overall_scatter_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created base directory for evaluation plots at 'evaluation_plots'.\n",
      "Created run-specific directory at 'evaluation_plots/run_20241118_213501'.\n",
      "Created 1759 sequences for evaluation.\n",
      "Evaluation split: 352 samples.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
      "Generated predictions for the test set.\n",
      "5-Minute Ahead Prediction - RMSE: 96.40, MAE: 73.15, R²: 0.73\n",
      "Saved plot: evaluation_plots/run_20241118_213501/5_min_ahead_prediction.png\n",
      "Saved scatter plot: evaluation_plots/run_20241118_213501/actual_vs_predicted_5_min_ahead.png\n",
      "15-Minute Ahead Prediction - RMSE: 122.37, MAE: 96.39, R²: 0.57\n",
      "Saved plot: evaluation_plots/run_20241118_213501/15_min_ahead_prediction.png\n",
      "Saved scatter plot: evaluation_plots/run_20241118_213501/actual_vs_predicted_15_min_ahead.png\n",
      "30-Minute Ahead Prediction - RMSE: 125.33, MAE: 103.67, R²: 0.55\n",
      "Saved plot: evaluation_plots/run_20241118_213501/30_min_ahead_prediction.png\n",
      "Saved scatter plot: evaluation_plots/run_20241118_213501/actual_vs_predicted_30_min_ahead.png\n",
      "60-Minute Ahead Prediction - RMSE: 137.10, MAE: 108.87, R²: 0.51\n",
      "Saved plot: evaluation_plots/run_20241118_213501/60_min_ahead_prediction.png\n",
      "Saved scatter plot: evaluation_plots/run_20241118_213501/actual_vs_predicted_60_min_ahead.png\n",
      "Overall Performance - RMSE: 121.21, MAE: 95.52, R²: 0.59\n",
      "Saved overall scatter plot: evaluation_plots/run_20241118_213501/actual_vs_predicted_overall.png\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, merged_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
